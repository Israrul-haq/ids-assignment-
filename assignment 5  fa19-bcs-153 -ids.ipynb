{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMOohCqT7ptv+qpgBM8YlSy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":73,"metadata":{"id":"tch_SvB_gPVQ","executionInfo":{"status":"ok","timestamp":1672405878895,"user_tz":-300,"elapsed":476,"user":{"displayName":"best master","userId":"11312665647503875653"}}},"outputs":[],"source":["#import libraries\n","from sklearn import preprocessing\n","import pandas as pd\n","import re\n","import nltk\n","import numpy\n","#import different ML classifiers\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","\n","#import ML evaluation metrics\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics, model_selection"]},{"cell_type":"code","source":["S1 = \"sunshine state enjoy sunshine\"\n","S2 = \"brown fox jump high, brown fox run\"\n","S3 = \"sunshine state fox run fast\"\n","\n","sentences =[S1,S2,S3]\n","def word_extraction(S1):\n","      ignore = ['a', \"the\", \"is\"]    \n","      words = re.sub(\"[^\\w]\", \" \",  S1).split()    \n","      cleaned_text = [w.lower() for w in words if w not in ignore]  \n","      return cleaned_text\n","\n","word_extraction(S1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cnHosNowkZpR","executionInfo":{"status":"ok","timestamp":1672409161396,"user_tz":-300,"elapsed":372,"user":{"displayName":"best master","userId":"11312665647503875653"}},"outputId":"60004001-7ff2-416a-cb7f-ec9c81919cc0"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['sunshine', 'state', 'enjoy', 'sunshine']"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["def tokenize(sentences):\n","      words = []\n","      for sentence in sentences:\n","        w=word_extraction(sentence)\n","        words.extend(w)            \n","        words = sorted(list(set(words)))    \n","      return words\n","      \n","tokenize(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IsbDqBwjt8ls","executionInfo":{"status":"ok","timestamp":1672409164573,"user_tz":-300,"elapsed":420,"user":{"displayName":"best master","userId":"11312665647503875653"}},"outputId":"c7f9931f-c00c-4755-f4a5-7931ec33fdef"},"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['brown', 'enjoy', 'fast', 'fox', 'high', 'jump', 'run', 'state', 'sunshine']"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["def generate_bow(allsentences):        \n","  vocab = tokenize(allsentences)    \n","  bag_vector = numpy.zeros(len(vocab))    \n","  print(\"Word List for Document \\n{0} \\n\".format(vocab));\n","  for sentence in allsentences:        \n","    words = word_extraction(sentence)             \n","    for w in words:            \n","      for i,word in enumerate(vocab):                \n","        if word == w:                     \n","          bag_vector[i] += 1                            \n","          print(\"{0}{1}\".format(sentence,numpy.array(bag_vector)))\n","\n"],"metadata":{"id":"Pym6uDJyu0Gt","executionInfo":{"status":"ok","timestamp":1672409167877,"user_tz":-300,"elapsed":374,"user":{"displayName":"best master","userId":"11312665647503875653"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["generate_bow(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mu4gP-N-wjRf","executionInfo":{"status":"ok","timestamp":1672409171712,"user_tz":-300,"elapsed":366,"user":{"displayName":"best master","userId":"11312665647503875653"}},"outputId":"198151b7-e23b-4785-891e-d01cc98ac2ea"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["Word List for Document \n","['brown', 'enjoy', 'fast', 'fox', 'high', 'jump', 'run', 'state', 'sunshine'] \n","\n","sunshine state enjoy sunshine[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n","sunshine state enjoy sunshine[0. 0. 0. 0. 0. 0. 0. 1. 1.]\n","sunshine state enjoy sunshine[0. 1. 0. 0. 0. 0. 0. 1. 1.]\n","sunshine state enjoy sunshine[0. 1. 0. 0. 0. 0. 0. 1. 2.]\n","brown fox jump high, brown fox run[1. 1. 0. 0. 0. 0. 0. 1. 2.]\n","brown fox jump high, brown fox run[1. 1. 0. 1. 0. 0. 0. 1. 2.]\n","brown fox jump high, brown fox run[1. 1. 0. 1. 0. 1. 0. 1. 2.]\n","brown fox jump high, brown fox run[1. 1. 0. 1. 1. 1. 0. 1. 2.]\n","brown fox jump high, brown fox run[2. 1. 0. 1. 1. 1. 0. 1. 2.]\n","brown fox jump high, brown fox run[2. 1. 0. 2. 1. 1. 0. 1. 2.]\n","brown fox jump high, brown fox run[2. 1. 0. 2. 1. 1. 1. 1. 2.]\n","sunshine state fox run fast[2. 1. 0. 2. 1. 1. 1. 1. 3.]\n","sunshine state fox run fast[2. 1. 0. 2. 1. 1. 1. 2. 3.]\n","sunshine state fox run fast[2. 1. 0. 3. 1. 1. 1. 2. 3.]\n","sunshine state fox run fast[2. 1. 0. 3. 1. 1. 2. 2. 3.]\n","sunshine state fox run fast[2. 1. 1. 3. 1. 1. 2. 2. 3.]\n"]}]},{"cell_type":"markdown","source":["## **`Question no 1 prt 2`**"],"metadata":{"id":"2duwYt0tV_PR"}},{"cell_type":"code","source":["\n","# import required module\n","from sklearn.feature_extraction.text import TfidfVectorizer"],"metadata":{"id":"3ecBJw3bWK_F","executionInfo":{"status":"ok","timestamp":1672409321800,"user_tz":-300,"elapsed":386,"user":{"displayName":"best master","userId":"11312665647503875653"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["\n","# create object\n","tfidf = TfidfVectorizer()\n"," \n","# get tf-df values\n","result = tfidf.fit_transform(sentences)"],"metadata":{"id":"Ux7BeBK5W4HC","executionInfo":{"status":"ok","timestamp":1672409323645,"user_tz":-300,"elapsed":380,"user":{"displayName":"best master","userId":"11312665647503875653"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["# get idf values\n","print('\\nidf values:')\n","for ele1, ele2 in zip(tfidf.get_feature_names(), tfidf.idf_):\n","    print(ele1, ':', ele2)"],"metadata":{"id":"pgNHYL1DXBRL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# get indexing\n","print('\\nWord indexes:')\n","print(tfidf.vocabulary_)\n"," \n","# display tf-idf values\n","print('\\ntf-idf value:')\n","print(result)\n"," \n","# in matrix form\n","print('\\ntf-idf values in matrix form:')\n","print(result.toarray())"],"metadata":{"id":"mmrqoRDYXgej"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **`Question no 2`**\n","âœ”\n","`find cosign semilirity in S! and S3`"],"metadata":{"id":"qP8xuPXRejXB"}},{"cell_type":"code","source":["# import required libraries\n","import numpy as np\n","from numpy.linalg import norm\n","import math\n","\n","std_embeddings_index = {}\n","\n","\n","def cosineValue(v1,v2):\n","    \"compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n","    sumxx, sumxy, sumyy = 0, 0, 0\n","    for i in range(len(v1)):\n","        x = v1[i]; y = v2[i]\n","        sumxx += x*x\n","        sumyy += y*y\n","        sumxy += x*y\n","    return sumxy/math.sqrt(sumxx*sumyy)\n","\n","\n","def get_sentence_vector(sentence, std_embeddings_index = std_embeddings_index ):\n","    sent_vector = 0\n","    for word in sentence.lower().split():\n","        if word not in std_embeddings_index :\n","            word_vector = np.array(np.random.uniform(-1.0, 1.0, 300))\n","            std_embeddings_index[word] = word_vector\n","        else:\n","            word_vector = std_embeddings_index[word]\n","        sent_vector = sent_vector + word_vector\n","\n","    return sent_vector\n","\n","def cosine_sim(S1, S2):\n","    return cosineValue(get_sentence_vector(S1), get_sentence_vector(S2))\n","\n","cosine_sim(S1, S3)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g4EslQBye-FH","executionInfo":{"status":"ok","timestamp":1672412356873,"user_tz":-300,"elapsed":398,"user":{"displayName":"best master","userId":"11312665647503875653"}},"outputId":"072aed9a-508f-40ea-a285-9bb852e94f76"},"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.539129542016981"]},"metadata":{},"execution_count":95}]}]}